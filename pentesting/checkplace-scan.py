#!/usr/bin/env python
# A basic ZAP Python API example which spiders and scans a target URL

import time
import requests
import sys
from pprint import pprint
from zapv2 import ZAPv2

target = 'http://localhost:4200'
proxy = 'http://127.0.0.1:8088'
apikey = 'xxxxxxxxxxxxx'  # Change to match the API key set in ZAP, or use None if the API key is disabled

# MANDATORY. Set True to use Ajax Spider, False otherwise.
useSeleniumScript = True
print_context = False
use_normal_spider = True
use_ajax_spider = True
run_passive_scan = True
run_active_scan = True
generate_report = True
define_new_context = True

contextName = "checkplace"
MINUTES_AJAX = 2

contextIncludeURL = [target + '.*',
                     'http://localhost:8099.*']
# Define Context Exclude URL regular expressions. Ignored if useContextForScan
# is False. List can be empty. It can be useful when we want to test only one view.
contextExcludeURL = []

authScriptName = 'checkplace-selenium.js'
authScriptEngine = 'Oracle Nashorn'
authScriptFileName = '/home/sebas/tas/source/eclipse-workspace/checkplace-be/pentesting/checkplace-selenium.js'
authScriptDescription = 'This is the script used to authenticate'

# Use the line below if ZAP is not listening on port 8080, for example, if listening on port 8090
zap = ZAPv2(apikey=apikey, proxies={'http': proxy, 'https': proxy})
headers = {
    'Accept': 'application/json',
    'X-ZAP-API-Key': apikey
}


def main(argv):
    # Executing selenium script
    if useSeleniumScript:
        print("Executing selenium script")
        execute_script()
        print("End execution selenium script")

    print("Creating the context")
    context = zap.context
    context_id = context.new_context(contextname=contextName)

    # Include URL in the context
    print('Include URL in context:')
    for url in contextIncludeURL:
        pprint(url + ' -> ' +
               context.include_in_context(contextname=contextName,
                                          regex=url))

    # Exclude URL in the context
    print('Exclude URL from context:')
    for url in contextExcludeURL:
        pprint(url + ' -> ' +
               context.exclude_from_context(contextname=contextName, regex=url))
    time.sleep(5)

    if print_context:
        print_context_info()

    # Proxy a request to the target so that ZAP has something to deal with neccesary??
    print('Accessing target {}'.format(target))
    zap.urlopen(target)
    # Give the sites tree a chance to get updated
    time.sleep(2)

    if use_normal_spider:
        print('Spider target {}'.format(target))
        normal_spider()
        print('Spider completed')

    if use_ajax_spider:
        print('Ajax Spider target {}'.format(target))
        print('Ajax Spider will take (seconds) {}'.format(MINUTES_AJAX * 60))
        ajax_spider()
        print('Ajax Spider completed')

    if run_passive_scan:
        print('Passive Scanning target {}'.format(target))
        passive_scan()
        print('Passive Scan completed')

    if run_active_scan:
        print('Active Scanning target {}'.format(target))
        active_scan(context_id)
        print('Active Scan completed')

    if generate_report:
        generate_info()

    print("Analysis finished")


def normal_spider():
    requests.get(proxy + '/JSON/spider/action/scan/', params={
        'url': target, 'recurse': True
    }, headers=headers)
    status = 0
    while status < 100:
        r = requests.get(proxy + '/JSON/spider/view/status/', params={
        }, headers=headers)
        if 'status' in r.json():
            status = int(r.json()['status'])
            if status % 20 == 0:
                print('Spider progress %: {}'.format(status))
    time.sleep(20)


def ajax_spider():
    ajax = zap.ajaxSpider
    ajax.scan(target)
    timeout = time.time() + 60 * MINUTES_AJAX  # X minutes from now
    # Loop until the ajax spider has finished or the timeout has exceeded
    while ajax.status == 'running':
        if time.time() > timeout:
            break
    print('Ajax Spider status ' + ajax.status)
    time.sleep(20)


def passive_scan():
    while int(zap.pscan.records_to_scan) > 0:
        if int(zap.pscan.records_to_scan) % 10 == 0:
            print('Records to passive scan : {}'.format(zap.pscan.records_to_scan))
    time.sleep(20)


def active_scan(context_id):
    requests.get(proxy + '/JSON/ascan/action/scan/', params={
        'url': target, 'recurse': True, 'contextId': context_id
    }, headers=headers)
    status = 0
    while status < 100:
        r = requests.get(proxy + '/JSON/ascan/view/status/', params={
        }, headers=headers)
        if 'status' in r.json():
            status = int(r.json()['status'])
    time.sleep(20)


def print_context_info():
    pprint('Use context with information:')
    r = requests.get(proxy + '/JSON/context/view/urls/', params={
        'contextName': contextName
    }, headers=headers)
    print(r.json())

    r = requests.get(proxy + '/JSON/context/view/context/', params={
        'contextName': contextName
    }, headers=headers)
    print(r.json())


def execute_script():
    requests.get(proxy + '/JSON/script/action/remove/', params={
        'scriptName': authScriptName
    }, headers=headers)

    requests.get(proxy + '/JSON/script/action/load/', params={
        'scriptName': authScriptName, 'scriptType': 'standalone', 'scriptEngine': authScriptEngine,
        'fileName': authScriptFileName
    }, headers=headers)

    r = requests.get(proxy + '/JSON/script/action/runStandAloneScript/', params={
        'scriptName': authScriptName
    }, headers=headers)
    print(r.json())
    time.sleep(20)


def generate_info():
    r = requests.get(proxy + '/JSON/alert/view/alertsSummary/', params={
        'baseurl': target
    }, headers=headers)
    print(r.json())


if __name__ == '__main__':
    main(sys.argv[0])
